{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOHhiKcwCnAARsdFQs5eCRH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"idfpfRIw2WXn","executionInfo":{"status":"ok","timestamp":1744022672495,"user_tz":-330,"elapsed":109,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"3103abcb-43d1-422a-b1f7-15714d09a6a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2024 NVIDIA Corporation\n","Built on Thu_Jun__6_02:18:23_PDT_2024\n","Cuda compilation tools, release 12.5, V12.5.82\n","Build cuda_12.5.r12.5/compiler.34385749_0\n"]}],"source":["!nvcc --version"]},{"cell_type":"code","source":["%%writefile firstprogram.cu\n","#include <stdio.h>\n","\n","#include <stdlib.h>\n","\n","int main()\n","\n","{\n","\n","int deviceCount;\n","\n","cudaGetDeviceCount(&deviceCount);\n","\n","if (deviceCount == 0)\n","\n","{\n","\n","printf(\"There is no device supporting CUDA\\n\");\n","\n","}\n","\n","int dev;\n","\n","for (dev = 0; dev < deviceCount; ++dev)\n","\n","{\n","\n","cudaDeviceProp deviceProp;\n","\n","cudaGetDeviceProperties(&deviceProp, dev);\n","\n","if (dev == 0)\n","\n","{\n","\n","if (deviceProp.major < 1)\n","\n","{\n","\n","printf(\"There is no device supporting CUDA.\\n\");\n","\n","}\n","\n","else if (deviceCount == 1)\n","\n","{\n","\n","printf(\"There is 1 device supporting CUDA\\n\");\n","\n","}\n","\n","else\n","\n","{\n","\n","printf(\"There are %d devices supporting CUDA\\n\", deviceCount);\n","\n","}\n","\n","}\n","\n","printf(\"\\nDevice %d: \\\"%s\\\"\\n\", dev, deviceProp.name);\n","\n","printf(\" Major revision number: %d\\n\", deviceProp.major);\n","\n","printf(\" Minor revision number: %d\\n\", deviceProp.minor);\n","\n","printf(\" Total amount of global memory: %ld bytes\\n\", deviceProp.totalGlobalMem);\n","\n","printf(\" Total amount of constant memory: %ld bytes\\n\", deviceProp.totalConstMem);\n","\n","printf(\" Total amount of shared memory per block: %ld bytes\\n\", deviceProp.sharedMemPerBlock);\n","\n","printf(\" Total number of registers available per block: %d\\n\", deviceProp.regsPerBlock);\n","\n","printf(\" Warp size: %d\\n\", deviceProp.warpSize);\n","\n","printf(\" Multiprocessor count: %d\\n\",deviceProp.multiProcessorCount );\n","\n","\n","printf(\" Maximum number of threads per block: %d\\n\", deviceProp.maxThreadsPerBlock);\n","\n","printf(\" Maximum sizes of each dimension of a block: %d x %d x %d\\n\", deviceProp.maxThreadsDim[0],deviceProp.maxThreadsDim[1], deviceProp.maxThreadsDim[2]);\n","\n","printf(\" Maximum sizes of each dimension of a grid: %d x %d x %d\\n\", deviceProp.maxGridSize[0], deviceProp.maxGridSize[1], deviceProp.maxGridSize[2]);\n","\n","printf(\" Maximum memory pitch: %ld bytes\\n\", deviceProp.memPitch);\n","\n","printf(\" Texture alignment: %ld bytes\\n\", deviceProp.textureAlignment);\n","\n","printf(\" Clock rate: %d kilohertz\\n\", deviceProp.clockRate);\n","\n","}\n","\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EuE_ld4T2sKc","executionInfo":{"status":"ok","timestamp":1744176064755,"user_tz":-330,"elapsed":33,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"1579a0e9-342e-4fe4-c130-c164005cc93e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing firstprogram.cu\n"]}]},{"cell_type":"code","source":["!nvcc -o p1 firstprogram.cu"],"metadata":{"id":"J2yQBSKk61Uc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! ./p1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6mNzOhaT9PPk","executionInfo":{"status":"ok","timestamp":1744176078631,"user_tz":-330,"elapsed":133,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"f02b9e18-fdeb-45c2-ed83-eb4644f2c33d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There is 1 device supporting CUDA\n","\n","Device 0: \"Tesla T4\"\n"," Major revision number: 7\n"," Minor revision number: 5\n"," Total amount of global memory: 15828320256 bytes\n"," Total amount of constant memory: 65536 bytes\n"," Total amount of shared memory per block: 49152 bytes\n"," Total number of registers available per block: 65536\n"," Warp size: 32\n"," Multiprocessor count: 40\n"," Maximum number of threads per block: 1024\n"," Maximum sizes of each dimension of a block: 1024 x 1024 x 64\n"," Maximum sizes of each dimension of a grid: 2147483647 x 65535 x 65535\n"," Maximum memory pitch: 2147483647 bytes\n"," Texture alignment: 512 bytes\n"," Clock rate: 1590000 kilohertz\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NgbbbK1W9X2j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile secondprogram.cu\n","#include <stdio.h>\n","\n","#include <cuda_runtime.h>\n","\n","__global__ void helloWorldKernel() {\n","    // Get the thread ID within the block\n","    int threadId = threadIdx.x;\n","\n","    // Print the thread ID and \"Hello World\"\n","    printf(\"Hello, World! from thread %d\\n\", threadId);\n","}\n","\n","\n","int main() {\n","    // Define the number of threads per block\n","    int numThreads = 10; // You can adjust this to any number of threads\n","\n","    // Launch the kernel with 1 block and `numThreads` threads\n","    helloWorldKernel<<<1, numThreads>>>();\n","\n","    // Wait for GPU to finish before accessing the results\n","   // =();\n","\n","\n","    cudaError_t err = cudaDeviceSynchronize();\n","    if (err != cudaSuccess) {\n","    printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n","}\n","    return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TCXeucRT7Jm8","executionInfo":{"status":"ok","timestamp":1744428533631,"user_tz":-330,"elapsed":59,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"10a76958-0d8a-4fa4-a667-10a0c2593e65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing secondprogram.cu\n"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 -o sp secondprogram.cu"],"metadata":{"id":"L8DhLips7rkf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run the compiled executable\n","!./sp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hCvkxYG_7zms","executionInfo":{"status":"ok","timestamp":1744428563237,"user_tz":-330,"elapsed":315,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"dc1803cd-c0b4-4850-d947-e509ddfb16ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello, World! from thread 0\n","Hello, World! from thread 1\n","Hello, World! from thread 2\n","Hello, World! from thread 3\n","Hello, World! from thread 4\n","Hello, World! from thread 5\n","Hello, World! from thread 6\n","Hello, World! from thread 7\n","Hello, World! from thread 8\n","Hello, World! from thread 9\n"]}]},{"cell_type":"code","source":["%%writefile thirdprogram.cu\n","#include <stdio.h>\n","#include <cuda_runtime.h>\n","\n","// Kernel function that each thread will execute\n","__global__ void helloWorldKernel() {\n","    // Get the global thread ID (unique for all threads)\n","    int globalThreadId = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    // Print the thread ID and \"Hello World\"\n","    //printf(\"Hello, World! from thread %d\\n\", globalThreadId);\n","    printf(\"Hello World from Block %d, Thread %d (Global ID: %d)\\n\", blockIdx.x, threadIdx.x, globalThreadId);\n","}\n","\n","int main() {\n","    // Define the number of threads per block and number of blocks\n","    int threadsPerBlock = 2;  // Threads per block\n","    int numBlocks = 2;         // Number of blocks\n","\n","    // Launch the kernel with multiple blocks and multiple threads per block\n","    helloWorldKernel<<<numBlocks, threadsPerBlock>>>();\n","\n","    // Wait for GPU to finish before accessing the results\n","    cudaDeviceSynchronize();\n","\n","    return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MhT-XAybB0g1","executionInfo":{"status":"ok","timestamp":1744429253932,"user_tz":-330,"elapsed":12,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"bdf1f7d6-8d71-4f4a-de90-35a02475b6bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting thirdprogram.cu\n"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 -o sp thirdprogram.cu\n"],"metadata":{"id":"M_08xC9QB_u0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!./sp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rWemuXw8CGlk","executionInfo":{"status":"ok","timestamp":1744429265058,"user_tz":-330,"elapsed":323,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"c2bb4753-9948-4b47-862d-0f9e42045060"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello World from Block 0, Thread 0 (Global ID: 0)\n","Hello World from Block 0, Thread 1 (Global ID: 1)\n","Hello World from Block 1, Thread 0 (Global ID: 2)\n","Hello World from Block 1, Thread 1 (Global ID: 3)\n"]}]},{"cell_type":"code","source":["%%writefile hello2D.cu\n","#include <stdio.h>\n","#include <cuda_runtime.h>\n","\n","__global__ void hello2D() {\n","\n","\n","    int global_x = threadIdx.x + blockIdx.x * blockDim.x;\n","    int global_y = threadIdx.y + blockIdx.y * blockDim.y;\n","\n","\n","    printf(\"Hello from thread (%d, %d) in block (%d, %d) -> Global ID (%d, %d)\\n\",\n","           threadIdx.x, threadIdx.y, blockIdx.x, blockIdx.y, global_x, global_y);\n","\n","\n","}\n","\n","int main() {\n","    dim3 threadsPerBlock(2, 2); // 2x2 = 4 threads per block\n","    dim3 numBlocks(2, 2);       // 2x2 = 4 blocks in the grid\n","\n","    hello2D<<<numBlocks, threadsPerBlock>>>();\n","    cudaDeviceSynchronize();\n","    return 0;\n","}\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJXhlUTyBpx4","executionInfo":{"status":"ok","timestamp":1744434151812,"user_tz":-330,"elapsed":48,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"6aaba658-4061-4fd8-ae24-dd3542c6552c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing hello2D.cu\n"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 -o sp hello2D.cu"],"metadata":{"id":"A3KZv5EhBzAf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!./sp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pd1b-vutCCxe","executionInfo":{"status":"ok","timestamp":1744434158357,"user_tz":-330,"elapsed":310,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"e8a2d8b4-109e-4758-d10d-ad745ddf60c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello from thread (0, 0) in block (0, 1) -> Global ID (0, 2)\n","Hello from thread (1, 0) in block (0, 1) -> Global ID (1, 2)\n","Hello from thread (0, 1) in block (0, 1) -> Global ID (0, 3)\n","Hello from thread (1, 1) in block (0, 1) -> Global ID (1, 3)\n","Hello from thread (0, 0) in block (0, 0) -> Global ID (0, 0)\n","Hello from thread (1, 0) in block (0, 0) -> Global ID (1, 0)\n","Hello from thread (0, 1) in block (0, 0) -> Global ID (0, 1)\n","Hello from thread (1, 1) in block (0, 0) -> Global ID (1, 1)\n","Hello from thread (0, 0) in block (1, 1) -> Global ID (2, 2)\n","Hello from thread (1, 0) in block (1, 1) -> Global ID (3, 2)\n","Hello from thread (0, 1) in block (1, 1) -> Global ID (2, 3)\n","Hello from thread (1, 1) in block (1, 1) -> Global ID (3, 3)\n","Hello from thread (0, 0) in block (1, 0) -> Global ID (2, 0)\n","Hello from thread (1, 0) in block (1, 0) -> Global ID (3, 0)\n","Hello from thread (0, 1) in block (1, 0) -> Global ID (2, 1)\n","Hello from thread (1, 1) in block (1, 0) -> Global ID (3, 1)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"BRxc7eb7DpU-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile VectorAddition.cu\n","#include <stdio.h>\n","#include <cuda_runtime.h>\n","\n","#define N 10  // Size of the vectors, can be adjusted\n","\n","// CUDA kernel to perform element-wise addition of two vectors A and B\n","__global__ void vectorAdd(int *A, int *B, int *C, int n) {\n","    // Get the thread index\n","    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n","\n","    // Ensure the thread index is within bounds\n","    if (idx < n) {\n","        C[idx] = A[idx] + B[idx];\n","    }\n","}\n","\n","int main() {\n","    // Host vectors\n","    int h_A[N], h_B[N], h_C[N];\n","\n","    // Initialize vectors A and B\n","    for (int i = 0; i < N; i++) {\n","        h_A[i] = i;        // Vector A: 0, 1, 2, ...\n","        h_B[i] = i * 2;    // Vector B: 0, 2, 4, ...\n","    }\n","\n","    // Device vectors\n","    int *d_A, *d_B, *d_C;\n","\n","    // Allocate memory on the GPU for vectors A, B, and C\n","    cudaMalloc((void**)&d_A, N * sizeof(int));\n","    cudaMalloc((void**)&d_B, N * sizeof(int));\n","    cudaMalloc((void**)&d_C, N * sizeof(int));\n","\n","    // Copy vectors A and B from host to device\n","    cudaMemcpy(d_A, h_A, N * sizeof(int), cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_B, h_B, N * sizeof(int), cudaMemcpyHostToDevice);\n","\n","    // Define block size (number of threads per block)\n","    int blockSize = 256;  // Max threads per block\n","    int numBlocks = (N + blockSize - 1) / blockSize;  // Calculate number of blocks\n","\n","    // Launch the kernel\n","    vectorAdd<<<numBlocks, blockSize>>>(d_A, d_B, d_C, N);\n","\n","    // Check for kernel launch errors\n","    cudaDeviceSynchronize();\n","\n","    // Copy the result vector C from device to host\n","    cudaMemcpy(h_C, d_C, N * sizeof(int), cudaMemcpyDeviceToHost);\n","\n","    // Print the result\n","    printf(\"Vector A: \");\n","    for (int i = 0; i < N; i++) {\n","        printf(\"%d \", h_A[i]);\n","    }\n","    printf(\"\\n\");\n","\n","    printf(\"Vector B: \");\n","    for (int i = 0; i < N; i++) {\n","        printf(\"%d \", h_B[i]);\n","    }\n","    printf(\"\\n\");\n","\n","    printf(\"Result Vector C (A + B): \");\n","    for (int i = 0; i < N; i++) {\n","        printf(\"%d \", h_C[i]);\n","    }\n","    printf(\"\\n\");\n","\n","    // Free device memory\n","    cudaFree(d_A);\n","    cudaFree(d_B);\n","    cudaFree(d_C);\n","\n","    return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WD9ELPFoDZzG","executionInfo":{"status":"ok","timestamp":1744177073201,"user_tz":-330,"elapsed":39,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"e663297d-297a-466f-af03-44d7bd427cb4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing VectorAddition.cu\n"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 -o sp VectorAddition.cu"],"metadata":{"id":"IY-etmZcDiDP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!./sp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Gx-vKnnDqho","executionInfo":{"status":"ok","timestamp":1744177116650,"user_tz":-330,"elapsed":222,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"85112aed-9729-4ac2-e7e9-724e878fc753"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vector A: 0 1 2 3 4 5 6 7 8 9 \n","Vector B: 0 2 4 6 8 10 12 14 16 18 \n","Result Vector C (A + B): 0 3 6 9 12 15 18 21 24 27 \n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"8hekYa1IvUwx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile VectorAdditionSerialAndParallel.cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <time.h>\n","#include <cuda_runtime.h>\n","\n","// CUDA kernel for vector addition\n","__global__ void vectorAddCUDA(float *A, float *B, float *C, int N) {\n","    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n","    if (idx < N)\n","        C[idx] = A[idx] + B[idx];\n","}\n","\n","// Serial CPU implementation of vector addition\n","void vectorAddCPU(float *A, float *B, float *C, int N) {\n","    for (int i = 0; i < N; i++) {\n","        C[i] = A[i] + B[i];\n","    }\n","}\n","\n","int main() {\n","    int Ns[] = {100000, 1000000, 10000000}; // Test with different sizes\n","\n","    for (int test = 0; test < 3; test++) {\n","        int N = Ns[test];\n","        size_t size = N * sizeof(float);\n","        printf(\"\\n========== N = %d ==========\\n\", N);\n","\n","        // Allocate host memory\n","        float *h_A = (float *)malloc(size);\n","        float *h_B = (float *)malloc(size);\n","        float *h_C_CPU = (float *)malloc(size);\n","        float *h_C_GPU = (float *)malloc(size);\n","\n","        // Initialize input vectors\n","        for (int i = 0; i < N; i++) {\n","            h_A[i] = i * 1.0f;\n","            h_B[i] = i * 2.0f;\n","        }\n","\n","        // -------------------- CPU Vector Addition --------------------\n","        clock_t start_cpu = clock();\n","        vectorAddCPU(h_A, h_B, h_C_CPU, N);\n","        clock_t end_cpu = clock();\n","        double time_cpu = ((double)(end_cpu - start_cpu)) / CLOCKS_PER_SEC;\n","        printf(\"CPU Time: %f seconds\\n\", time_cpu);\n","\n","        // -------------------- GPU Vector Addition --------------------\n","        float *d_A, *d_B, *d_C;\n","        cudaMalloc((void **)&d_A, size);\n","        cudaMalloc((void **)&d_B, size);\n","        cudaMalloc((void **)&d_C, size);\n","\n","        // Copy inputs to device\n","        cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n","        cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n","\n","        // CUDA timing events\n","        cudaEvent_t start_gpu, stop_gpu;\n","        cudaEventCreate(&start_gpu);\n","        cudaEventCreate(&stop_gpu);\n","        cudaEventRecord(start_gpu);\n","\n","        int threadsPerBlock = 256;\n","        int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n","\n","        vectorAddCUDA<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);\n","        cudaEventRecord(stop_gpu);\n","        cudaEventSynchronize(stop_gpu);\n","\n","        float time_gpu = 0;\n","        cudaEventElapsedTime(&time_gpu, start_gpu, stop_gpu);\n","        printf(\"GPU Time: %f milliseconds\\n\", time_gpu);\n","\n","        // Copy result back to host\n","        cudaMemcpy(h_C_GPU, d_C, size, cudaMemcpyDeviceToHost);\n","\n","        // Optional correctness check\n","        int errors = 0;\n","        for (int i = 0; i < N; i++) {\n","            if (abs(h_C_CPU[i] - h_C_GPU[i]) > 1e-5) {\n","                errors++;\n","                if (errors < 10) {\n","                    printf(\"Mismatch at index %d: CPU = %f, GPU = %f\\n\", i, h_C_CPU[i], h_C_GPU[i]);\n","                }\n","            }\n","        }\n","        if (errors == 0) {\n","            printf(\"✅ CPU and GPU results match!\\n\");\n","        } else {\n","            printf(\"❌ Mismatches found: %d\\n\", errors);\n","        }\n","\n","        // Free memory\n","        free(h_A); free(h_B); free(h_C_CPU); free(h_C_GPU);\n","        cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n","        cudaEventDestroy(start_gpu);\n","        cudaEventDestroy(stop_gpu);\n","    }\n","\n","    return 0;\n","}\n"],"metadata":{"id":"w_Kw8wwsDyYf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744440178533,"user_tz":-330,"elapsed":11,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"8ef8100f-50b0-4b4c-c71c-52fc5878df06"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing VectorAdditionSerialAndParallel.cu\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"EM5QaqVNBp5m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvcc -arch=sm_75 -o sp VectorAdditionSerialAndParallel.cu"],"metadata":{"id":"fZeaguljvMqN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!./sp"],"metadata":{"id":"iQykl4srvWCG","executionInfo":{"status":"ok","timestamp":1744440224745,"user_tz":-330,"elapsed":414,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"5554d4bc-0969-4487-a2cf-e5fa22c5bffa","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","========== N = 100000 ==========\n","CPU Time: 0.000809 seconds\n","GPU Time: 0.000000 milliseconds\n","Mismatch at index 1: CPU = 3.000000, GPU = 0.000000\n","Mismatch at index 2: CPU = 6.000000, GPU = 0.000000\n","Mismatch at index 3: CPU = 9.000000, GPU = 0.000000\n","Mismatch at index 4: CPU = 12.000000, GPU = 0.000000\n","Mismatch at index 5: CPU = 15.000000, GPU = 0.000000\n","Mismatch at index 6: CPU = 18.000000, GPU = 0.000000\n","Mismatch at index 7: CPU = 21.000000, GPU = 0.000000\n","Mismatch at index 8: CPU = 24.000000, GPU = 0.000000\n","Mismatch at index 9: CPU = 27.000000, GPU = 0.000000\n","❌ Mismatches found: 99999\n","\n","========== N = 1000000 ==========\n","CPU Time: 0.006473 seconds\n","GPU Time: 0.000000 milliseconds\n","Mismatch at index 1: CPU = 3.000000, GPU = 0.000000\n","Mismatch at index 2: CPU = 6.000000, GPU = 0.000000\n","Mismatch at index 3: CPU = 9.000000, GPU = 0.000000\n","Mismatch at index 4: CPU = 12.000000, GPU = 0.000000\n","Mismatch at index 5: CPU = 15.000000, GPU = 0.000000\n","Mismatch at index 6: CPU = 18.000000, GPU = 0.000000\n","Mismatch at index 7: CPU = 21.000000, GPU = 0.000000\n","Mismatch at index 8: CPU = 24.000000, GPU = 0.000000\n","Mismatch at index 9: CPU = 27.000000, GPU = 0.000000\n","❌ Mismatches found: 999999\n","\n","========== N = 10000000 ==========\n","CPU Time: 0.093109 seconds\n","GPU Time: 0.000000 milliseconds\n","Mismatch at index 1: CPU = 3.000000, GPU = 0.000000\n","Mismatch at index 2: CPU = 6.000000, GPU = 0.000000\n","Mismatch at index 3: CPU = 9.000000, GPU = 0.000000\n","Mismatch at index 4: CPU = 12.000000, GPU = 0.000000\n","Mismatch at index 5: CPU = 15.000000, GPU = 0.000000\n","Mismatch at index 6: CPU = 18.000000, GPU = 0.000000\n","Mismatch at index 7: CPU = 21.000000, GPU = 0.000000\n","Mismatch at index 8: CPU = 24.000000, GPU = 0.000000\n","Mismatch at index 9: CPU = 27.000000, GPU = 0.000000\n","❌ Mismatches found: 9999999\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"I7X3RP08CLuP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%writefile fifthprogram.cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <time.h>\n","#include <cuda_runtime.h>\n","\n","// Serial version of vector addition\n","void vector_add_cpu(float *A, float *B, float *C, int N) {\n","    for (int i = 0; i < N; i++) {\n","        C[i] = A[i] + B[i];\n","    }\n","}\n","\n","// CUDA kernel for vector addition\n","__global__ void vector_add_cuda(float *A, float *B, float *C, int N) {\n","    int i = blockIdx.x * blockDim.x + threadIdx.x;\n","    if (i < N) {\n","        C[i] = A[i] + B[i];\n","    }\n","}\n","\n","int main() {\n","    // Different sizes of N to test\n","    int sizes[] = {100000, 1000000, 10000000};\n","    int num_sizes = sizeof(sizes) / sizeof(sizes[0]);\n","\n","    // Loop over different N sizes\n","    for (int s = 0; s < num_sizes; s++) {\n","        int N = sizes[s];\n","        float *A, *B, *C;\n","        float *d_A, *d_B, *d_C;\n","\n","        // Allocate memory for vectors on the host\n","        A = (float*)malloc(N * sizeof(float));\n","        B = (float*)malloc(N * sizeof(float));\n","        C = (float*)malloc(N * sizeof(float));\n","\n","        // Initialize random number generator\n","        srand(time(NULL));\n","\n","        // Initialize vectors A and B with random numbers\n","        for (int i = 0; i < N; i++) {\n","            A[i] = rand() % 1000;\n","            B[i] = rand() % 1000;\n","        }\n","\n","        // Run the CPU-based vector addition\n","        clock_t start_time = clock();\n","        vector_add_cpu(A, B, C, N);\n","        clock_t end_time = clock();\n","        double cpu_time = ((double)(end_time - start_time)) / CLOCKS_PER_SEC;\n","        printf(\"\\nFor N = %d, CPU execution time: %f seconds\\n\", N, cpu_time);\n","\n","        // Allocate memory on the GPU\n","        cudaMalloc((void**)&d_A, N * sizeof(float));\n","        cudaMalloc((void**)&d_B, N * sizeof(float));\n","        cudaMalloc((void**)&d_C, N * sizeof(float));\n","\n","        // Copy vectors A and B from host to device\n","        cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n","        cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);\n","\n","        // Define block and grid size\n","        int blockSize = 256;\n","        int gridSize = (N + blockSize - 1) / blockSize;\n","\n","        // Measure execution time for GPU-based implementation\n","        cudaEvent_t start, stop;\n","        cudaEventCreate(&start);\n","        cudaEventCreate(&stop);\n","        cudaEventRecord(start);\n","\n","        // Launch the CUDA kernel\n","        vector_add_cuda<<<gridSize, blockSize>>>(d_A, d_B, d_C, N);\n","\n","        // Wait for GPU to finish\n","        cudaDeviceSynchronize();\n","\n","        cudaEventRecord(stop);\n","        cudaEventSynchronize(stop);\n","\n","        float gpu_time;\n","        cudaEventElapsedTime(&gpu_time, start, stop);\n","        printf(\"GPU execution time: %f milliseconds\\n\", gpu_time);\n","\n","        // Copy the result from device to host\n","        cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n","\n","        // Free memory on the GPU\n","        cudaFree(d_A);\n","        cudaFree(d_B);\n","        cudaFree(d_C);\n","\n","        // Free memory on the host\n","        free(A);\n","        free(B);\n","        free(C);\n","\n","        // Calculate and report the speedup\n","        double speedup = cpu_time / (gpu_time / 1000.0); // Convert GPU time to seconds\n","        printf(\"Speedup: %f\\n\", speedup);\n","    }\n","\n","    return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qJiTLZqLBrlf","executionInfo":{"status":"ok","timestamp":1744495451536,"user_tz":-330,"elapsed":2,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"a91c3505-1141-4473-8135-cf57229e6ad4"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Writing fifthprogram.cu\n"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 -o sp fifthprogram.cu"],"metadata":{"id":"b4rXdEk4B9RW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!./sp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8uDe5CiECMnj","executionInfo":{"status":"ok","timestamp":1744495500794,"user_tz":-330,"elapsed":706,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"19ec91c8-495f-4b22-9bd7-fa1faf88a438"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","For N = 100000, CPU execution time: 0.000584 seconds\n","GPU execution time: 0.000000 milliseconds\n","Speedup: 1627954399492735387821024212502147848208384.000000\n","\n","For N = 1000000, CPU execution time: 0.005590 seconds\n","GPU execution time: 0.000000 milliseconds\n","Speedup: 15582645707473272524007270571691354634584064.000000\n","\n","For N = 10000000, CPU execution time: 0.060235 seconds\n","GPU execution time: 0.000000 milliseconds\n","Speedup: 167910673379186489224696619917750606657224704.000000\n"]}]},{"cell_type":"code","source":["%%writefile fifthprogram1.cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <time.h>\n","#include <cuda_runtime.h>\n","\n","// Serial version of vector addition\n","void vector_add_cpu(float *A, float *B, float *C, int N) {\n","    for (int i = 0; i < N; i++) {\n","        C[i] = A[i] + B[i];\n","    }\n","}\n","\n","// CUDA kernel for vector addition\n","__global__ void vector_add_cuda(float *A, float *B, float *C, int N) {\n","    int i = blockIdx.x * blockDim.x + threadIdx.x;\n","    if (i < N) {\n","        C[i] = A[i] + B[i];\n","    }\n","}\n","\n","int main() {\n","    int sizes[] = {100000, 1000000, 10000000};\n","    int num_sizes = sizeof(sizes) / sizeof(sizes[0]);\n","\n","    for (int s = 0; s < num_sizes; s++) {\n","        int N = sizes[s];\n","        float *A, *B, *C;\n","        float *d_A, *d_B, *d_C;\n","\n","        // Allocate host memory\n","        A = (float*)malloc(N * sizeof(float));\n","        B = (float*)malloc(N * sizeof(float));\n","        C = (float*)malloc(N * sizeof(float));\n","\n","        // Initialize random numbers\n","        srand((unsigned int)time(NULL));\n","        for (int i = 0; i < N; i++) {\n","            A[i] = rand() % 1000;\n","            B[i] = rand() % 1000;\n","        }\n","\n","        // CPU timing\n","        clock_t start_time = clock();\n","        vector_add_cpu(A, B, C, N);\n","        clock_t end_time = clock();\n","        double cpu_time = ((double)(end_time - start_time)) / CLOCKS_PER_SEC;\n","        printf(\"\\nFor N = %d, CPU execution time: %f seconds\\n\", N, cpu_time);\n","\n","        // Allocate device memory\n","        cudaMalloc((void**)&d_A, N * sizeof(float));\n","        cudaMalloc((void**)&d_B, N * sizeof(float));\n","        cudaMalloc((void**)&d_C, N * sizeof(float));\n","\n","        // Copy data to device\n","        cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n","        cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);\n","\n","        // Configure kernel\n","        int blockSize = 256;\n","        int gridSize = (N + blockSize - 1) / blockSize;\n","\n","        // Create CUDA events for timing\n","        cudaEvent_t start, stop;\n","        cudaEventCreate(&start);\n","        cudaEventCreate(&stop);\n","\n","        // Start timing and launch kernel\n","        cudaEventRecord(start);\n","        vector_add_cuda<<<gridSize, blockSize>>>(d_A, d_B, d_C, N);\n","        cudaEventRecord(stop);\n","\n","        // Check for kernel errors\n","        cudaError_t err = cudaGetLastError();\n","        if (err != cudaSuccess) {\n","            printf(\"CUDA Error: %s\\n\", cudaGetErrorString(err));\n","        }\n","\n","        // Wait for kernel to finish and get time\n","        cudaEventSynchronize(stop);\n","        float gpu_time;\n","        cudaEventElapsedTime(&gpu_time, start, stop);\n","\n","        printf(\"GPU execution time: %f milliseconds\\n\", gpu_time);\n","\n","        // Copy result back to host\n","        cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n","\n","        // Calculate speedup\n","        double speedup = cpu_time / (gpu_time / 1000.0); // Convert ms to sec\n","        printf(\"Speedup: %f\\n\", speedup);\n","\n","        // Cleanup\n","        cudaFree(d_A);\n","        cudaFree(d_B);\n","        cudaFree(d_C);\n","        free(A);\n","        free(B);\n","        free(C);\n","        cudaEventDestroy(start);\n","        cudaEventDestroy(stop);\n","    }\n","\n","    return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oOtEDscpsEvc","executionInfo":{"status":"ok","timestamp":1744506522102,"user_tz":-330,"elapsed":36,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"a61bf4c4-fe48-456e-f306-c59bb49853a4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing fifthprogram1.cu\n"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 -o sp fifthprogram1.cu"],"metadata":{"id":"slBabzDTsPyp","executionInfo":{"status":"ok","timestamp":1744506536445,"user_tz":-330,"elapsed":3042,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!./sp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1DouNmWsUds","executionInfo":{"status":"ok","timestamp":1744506553422,"user_tz":-330,"elapsed":936,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"bef60480-bc29-4bec-fa3e-c9b43b966d58"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","For N = 100000, CPU execution time: 0.000479 seconds\n","GPU execution time: 0.129856 milliseconds\n","Speedup: 3.688701\n","\n","For N = 1000000, CPU execution time: 0.004948 seconds\n","GPU execution time: 0.051584 milliseconds\n","Speedup: 95.921213\n","\n","For N = 10000000, CPU execution time: 0.055042 seconds\n","GPU execution time: 0.457632 milliseconds\n","Speedup: 120.275679\n"]}]},{"cell_type":"code","source":["%%writefile sixthprogram.cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda.h>\n","#include <time.h>\n","#include <math.h>\n","\n","__global__ void matrixAddCUDA(float* A, float* B, float* C, int M, int N) {\n","    int row = blockIdx.y * blockDim.y + threadIdx.y;\n","    int col = blockIdx.x * blockDim.x + threadIdx.x;\n","    if (row < M && col < N) {\n","        int idx = row * N + col;\n","        C[idx] = A[idx] + B[idx];\n","    }\n","}\n","\n","void matrixAddCPU(float* A, float* B, float* C, int M, int N) {\n","    for (int i = 0; i < M; ++i)\n","        for (int j = 0; j < N; ++j)\n","            C[i * N + j] = A[i * N + j] + B[i * N + j];\n","}\n","\n","void initMatrix(float* mat, int size) {\n","    for (int i = 0; i < size; ++i)\n","        mat[i] = (float)(rand() % 100);\n","}\n","\n","double getCPUTime() {\n","    struct timespec t;\n","    clock_gettime(CLOCK_MONOTONIC, &t);\n","    return (t.tv_sec * 1e3) + (t.tv_nsec / 1e6);  // milliseconds\n","}\n","\n","int main() {\n","    int sizes[] = {100, 500, 1000};  // Use provided sizes only\n","    int numSizes = sizeof(sizes) / sizeof(sizes[0]);\n","\n","    for (int s = 0; s < numSizes; ++s) {\n","        int M = sizes[s], N = sizes[s];\n","        int size = M * N * sizeof(float);\n","\n","        float *h_A = (float*)malloc(size);\n","        float *h_B = (float*)malloc(size);\n","        float *h_C_cpu = (float*)malloc(size);\n","        float *h_C_gpu = (float*)malloc(size);\n","\n","        initMatrix(h_A, M * N);\n","        initMatrix(h_B, M * N);\n","\n","        // CPU timing\n","        double cpu_start = getCPUTime();\n","        matrixAddCPU(h_A, h_B, h_C_cpu, M, N);\n","        double cpu_end = getCPUTime();\n","        double cpu_time = cpu_end - cpu_start;\n","\n","        // Allocate GPU memory\n","        float *d_A, *d_B, *d_C;\n","        cudaMalloc((void**)&d_A, size);\n","        cudaMalloc((void**)&d_B, size);\n","        cudaMalloc((void**)&d_C, size);\n","\n","        cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n","        cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n","\n","        dim3 blockSize(16, 16);\n","        dim3 gridSize((N + blockSize.x - 1) / blockSize.x,\n","                      (M + blockSize.y - 1) / blockSize.y);\n","\n","        cudaEvent_t start, stop;\n","        cudaEventCreate(&start);\n","        cudaEventCreate(&stop);\n","\n","        // GPU timing with correct event placement\n","        cudaEventRecord(start);\n","        matrixAddCUDA<<<gridSize, blockSize>>>(d_A, d_B, d_C, M, N);\n","        cudaEventRecord(stop);\n","\n","        // Error checking\n","        cudaError_t err = cudaGetLastError();\n","        if (err != cudaSuccess) {\n","            printf(\"CUDA kernel error: %s\\n\", cudaGetErrorString(err));\n","        }\n","\n","        cudaEventSynchronize(stop);\n","        float gpu_time;\n","        cudaEventElapsedTime(&gpu_time, start, stop);  // in milliseconds\n","\n","        cudaMemcpy(h_C_gpu, d_C, size, cudaMemcpyDeviceToHost);\n","\n","        // Check result correctness\n","        int error = 0;\n","        for (int i = 0; i < M * N; ++i) {\n","            if (fabs(h_C_cpu[i] - h_C_gpu[i]) > 1e-5) {\n","                error = 1;\n","                break;\n","            }\n","        }\n","\n","        // Safe speedup calculation\n","        double speedup = (gpu_time > 0.0) ? (cpu_time / gpu_time) : 0.0;\n","\n","        printf(\"Matrix size: %dx%d\\n\", M, N);\n","        printf(\"CPU Time: %.4f ms\\n\", cpu_time);\n","        printf(\"GPU Time: %.4f ms\\n\", gpu_time);\n","        printf(\"Speedup: %.2fx\\n\", speedup);\n","        printf(\"Result match: %s\\n\\n\", error ? \"No\" : \"Yes\");\n","\n","        // Cleanup\n","        free(h_A); free(h_B); free(h_C_cpu); free(h_C_gpu);\n","        cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n","        cudaEventDestroy(start); cudaEventDestroy(stop);\n","    }\n","\n","    return 0;\n","}\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zUM0stq3F9A9","executionInfo":{"status":"ok","timestamp":1744507193583,"user_tz":-330,"elapsed":26,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"b5b7a26a-10f7-4a75-81fd-e487bc25a968"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing sixthprogram.cu\n"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 -o sp sixthprogram.cu"],"metadata":{"id":"uhjLi8Q8GkC0","executionInfo":{"status":"ok","timestamp":1744507200117,"user_tz":-330,"elapsed":1201,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!./sp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MMSAffy_GqqX","executionInfo":{"status":"ok","timestamp":1744507202605,"user_tz":-330,"elapsed":311,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"103e6799-a3ca-4976-8913-b09791da2e2b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix size: 100x100\n","CPU Time: 0.0747 ms\n","GPU Time: 0.0938 ms\n","Speedup: 0.80x\n","Result match: Yes\n","\n","Matrix size: 500x500\n","CPU Time: 1.2672 ms\n","GPU Time: 0.0224 ms\n","Speedup: 56.49x\n","Result match: Yes\n","\n","Matrix size: 1000x1000\n","CPU Time: 5.1848 ms\n","GPU Time: 0.0555 ms\n","Speedup: 93.39x\n","Result match: Yes\n","\n"]}]},{"cell_type":"code","source":["%%writefile seventhprogram.cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda_runtime.h>\n","#include <time.h>\n","\n","#define BLOCK_SIZE 256\n","\n","// CUDA kernel for dot product using shared memory and atomicAdd\n","__global__ void dotProductKernel(float *A, float *B, float *result, int N) {\n","    __shared__ float cache[BLOCK_SIZE];\n","    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n","    int cacheIdx = threadIdx.x;\n","\n","    float temp = 0.0;\n","    while (tid < N) {\n","        temp += A[tid] * B[tid];\n","        tid += blockDim.x * gridDim.x;\n","    }\n","\n","    cache[cacheIdx] = temp;\n","    __syncthreads();\n","\n","    // Reduction within block\n","    int i = blockDim.x / 2;\n","    while (i != 0) {\n","        if (cacheIdx < i)\n","            cache[cacheIdx] += cache[cacheIdx + i];\n","        __syncthreads();\n","        i /= 2;\n","    }\n","\n","    // Add block result to global result\n","    if (cacheIdx == 0)\n","        atomicAdd(result, cache[0]);\n","}\n","\n","// Serial CPU implementation\n","float dotProductCPU(float *A, float *B, int N) {\n","    float sum = 0.0;\n","    for (int i = 0; i < N; ++i)\n","        sum += A[i] * B[i];\n","    return sum;\n","}\n","\n","// Function to initialize vectors with random floats\n","void initializeVectors(float *A, float *B, int N) {\n","    for (int i = 0; i < N; ++i) {\n","        A[i] = (float)(rand()) / RAND_MAX;\n","        B[i] = (float)(rand()) / RAND_MAX;\n","    }\n","}\n","\n","// Run and time both CPU and GPU dot product\n","void runDotProduct(int N) {\n","    float *h_A, *h_B;\n","    float *d_A, *d_B, *d_result;\n","    float gpu_result = 0.0, cpu_result = 0.0;\n","\n","    size_t size = N * sizeof(float);\n","\n","    // Allocate host memory\n","    h_A = (float*)malloc(size);\n","    h_B = (float*)malloc(size);\n","\n","    initializeVectors(h_A, h_B, N);\n","\n","    // CPU computation and timing\n","    clock_t cpu_start = clock();\n","    cpu_result = dotProductCPU(h_A, h_B, N);\n","    clock_t cpu_end = clock();\n","    double cpu_time = ((double)(cpu_end - cpu_start)) / CLOCKS_PER_SEC * 1000;  // Convert to ms\n","\n","    // Allocate device memory\n","    cudaMalloc((void**)&d_A, size);\n","    cudaMalloc((void**)&d_B, size);\n","    cudaMalloc((void**)&d_result, sizeof(float));\n","\n","    // Copy data to device\n","    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n","    cudaMemset(d_result, 0, sizeof(float));\n","\n","    // GPU computation and timing\n","    cudaEvent_t start, stop;\n","    cudaEventCreate(&start);\n","    cudaEventCreate(&stop);\n","    cudaEventRecord(start);\n","\n","    int numBlocks = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n","    dotProductKernel<<<numBlocks, BLOCK_SIZE>>>(d_A, d_B, d_result, N);\n","\n","    cudaEventRecord(stop);\n","    cudaEventSynchronize(stop);\n","\n","    float milliseconds = 0;\n","    cudaEventElapsedTime(&milliseconds, start, stop);\n","\n","    // Copy result back to host\n","    cudaMemcpy(&gpu_result, d_result, sizeof(float), cudaMemcpyDeviceToHost);\n","\n","    // Output results\n","    printf(\"Vector Size: %d\\n\", N);\n","    printf(\"CPU Result: %f, Time: %.3f ms\\n\", cpu_result, cpu_time);\n","    printf(\"GPU Result: %f, Time: %.3f ms\\n\", gpu_result, milliseconds);\n","    printf(\"Speedup: %.2fx\\n\\n\", cpu_time / milliseconds);\n","\n","    // Cleanup\n","    free(h_A); free(h_B);\n","    cudaFree(d_A); cudaFree(d_B); cudaFree(d_result);\n","}\n","\n","int main() {\n","    srand(time(NULL));\n","    int sizes[] = {100000, 1000000, 10000000};  // Different sizes of N\n","\n","    for (int i = 0; i < 3; ++i)\n","        runDotProduct(sizes[i]);\n","\n","    return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"daNWF9PWyv36","executionInfo":{"status":"ok","timestamp":1744508340048,"user_tz":-330,"elapsed":36,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"4e9b6bb0-49fb-4862-91d3-9e63059669b5"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting seventhprogram.cu\n"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 -o sp seventhprogram.cu"],"metadata":{"id":"IfNpUG-yzPs3","executionInfo":{"status":"ok","timestamp":1744508367215,"user_tz":-330,"elapsed":1241,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["!./sp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bogfHOq9zTDM","executionInfo":{"status":"ok","timestamp":1744508376181,"user_tz":-330,"elapsed":806,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"fa93ec67-8233-49fd-f0eb-7c38be5b305f"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Vector Size: 100000\n","CPU Result: 24868.974609, Time: 0.324 ms\n","GPU Result: 24869.150391, Time: 0.102 ms\n","Speedup: 3.18x\n","\n","Vector Size: 1000000\n","CPU Result: 249918.468750, Time: 3.038 ms\n","GPU Result: 249954.234375, Time: 0.107 ms\n","Speedup: 28.48x\n","\n","Vector Size: 10000000\n","CPU Result: 2471850.250000, Time: 30.714 ms\n","GPU Result: 2500996.000000, Time: 0.998 ms\n","Speedup: 30.76x\n","\n"]}]},{"cell_type":"code","source":["%%writefile eighthprogram.cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <time.h>\n","#include <cuda_runtime.h>\n","\n","#define TILE_SIZE 16  // Defining tile size for shared memory optimization\n","\n","// CUDA kernel for matrix multiplication\n","__global__ void matrixMultiplyCUDA(float* A, float* B, float* C, int M, int N, int P) {\n","    int row = blockIdx.y * blockDim.y + threadIdx.y;\n","    int col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if (row < M && col < P) {\n","        float value = 0;\n","        for (int k = 0; k < N; k++) {\n","            value += A[row * N + k] * B[k * P + col];\n","        }\n","        C[row * P + col] = value;\n","    }\n","}\n","\n","// Serial matrix multiplication on the CPU\n","void matrixMultiplySerial(float* A, float* B, float* C, int M, int N, int P) {\n","    for (int i = 0; i < M; i++) {\n","        for (int j = 0; j < P; j++) {\n","            C[i * P + j] = 0;\n","            for (int k = 0; k < N; k++) {\n","                C[i * P + j] += A[i * N + k] * B[k * P + j];\n","            }\n","        }\n","    }\n","}\n","\n","// Function to initialize a matrix with random values\n","void initializeMatrix(float* mat, int rows, int cols) {\n","    for (int i = 0; i < rows; i++) {\n","        for (int j = 0; j < cols; j++) {\n","            mat[i * cols + j] = rand() % 100;\n","        }\n","    }\n","}\n","\n","int main() {\n","    // Matrix sizes to test\n","    int matrix_sizes[][3] = {\n","        {100, 100, 100},\n","        {500, 500, 500},\n","        {1000, 1000, 1000}\n","    };\n","\n","    // Loop over different matrix sizes\n","    for (int idx = 0; idx < 3; idx++) {\n","        int M = matrix_sizes[idx][0]; // Rows of A and C\n","        int N = matrix_sizes[idx][1]; // Columns of A and Rows of B\n","        int P = matrix_sizes[idx][2]; // Columns of B and C\n","\n","        printf(\"\\nRunning matrix multiplication for size %dx%dx%d\\n\", M, N, P);\n","\n","        // Allocate memory for matrices on the host (CPU)\n","        float* A = (float*)malloc(M * N * sizeof(float));\n","        float* B = (float*)malloc(N * P * sizeof(float));\n","        float* C_serial = (float*)malloc(M * P * sizeof(float));\n","        float* C_cuda = (float*)malloc(M * P * sizeof(float));\n","\n","        // Initialize matrices A and B with random values\n","        srand(time(NULL));\n","        initializeMatrix(A, M, N);\n","        initializeMatrix(B, N, P);\n","\n","        // Measure the execution time for serial matrix multiplication\n","        clock_t start = clock();\n","        matrixMultiplySerial(A, B, C_serial, M, N, P);\n","        clock_t end = clock();\n","        double serial_time = (double)(end - start) / CLOCKS_PER_SEC;\n","        printf(\"Serial execution time: %f seconds\\n\", serial_time);\n","\n","        // Allocate memory for matrices on the device (GPU)\n","        float *d_A, *d_B, *d_C;\n","        cudaMalloc((void**)&d_A, M * N * sizeof(float));\n","        cudaMalloc((void**)&d_B, N * P * sizeof(float));\n","        cudaMalloc((void**)&d_C, M * P * sizeof(float));\n","\n","        // Copy matrices A and B from host to device\n","        cudaMemcpy(d_A, A, M * N * sizeof(float), cudaMemcpyHostToDevice);\n","        cudaMemcpy(d_B, B, N * P * sizeof(float), cudaMemcpyHostToDevice);\n","\n","        // Define the grid and block sizes for the kernel\n","        dim3 dimBlock(TILE_SIZE, TILE_SIZE);\n","        dim3 dimGrid((P + TILE_SIZE - 1) / TILE_SIZE, (M + TILE_SIZE - 1) / TILE_SIZE);\n","\n","        // Measure the execution time for parallel matrix multiplication (GPU)\n","        start = clock();\n","        matrixMultiplyCUDA<<<dimGrid, dimBlock>>>(d_A, d_B, d_C, M, N, P);\n","        cudaDeviceSynchronize();\n","        end = clock();\n","        double cuda_time = (double)(end - start) / CLOCKS_PER_SEC;\n","        printf(\"CUDA execution time: %f seconds\\n\", cuda_time);\n","\n","        // Copy the result matrix C from device to host\n","        cudaMemcpy(C_cuda, d_C, M * P * sizeof(float), cudaMemcpyDeviceToHost);\n","\n","        // Calculate speedup\n","        double speedup = serial_time / cuda_time;\n","        printf(\"Speedup: %f\\n\", speedup);\n","\n","        // Free device memory\n","        cudaFree(d_A);\n","        cudaFree(d_B);\n","        cudaFree(d_C);\n","\n","        // Free host memory\n","        free(A);\n","        free(B);\n","        free(C_serial);\n","        free(C_cuda);\n","    }\n","\n","    return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"collapsed":true,"id":"Cs3WKXbD4Jjx","executionInfo":{"status":"error","timestamp":1744510817313,"user_tz":-330,"elapsed":68,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"99059bda-265e-44f0-cf73-c95c15ac602f"},"execution_count":25,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'free' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-9ee087a8efb8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'free' is not defined"]}]},{"cell_type":"code","source":["!nvcc -arch=sm_75 -o sp eighthprogram.cu"],"metadata":{"id":"wvh0v3oC4-hM","executionInfo":{"status":"ok","timestamp":1744509867102,"user_tz":-330,"elapsed":1220,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["!./sp"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_0JNwelg5Bsq","executionInfo":{"status":"ok","timestamp":1744509886290,"user_tz":-330,"elapsed":8375,"user":{"displayName":"245510003 Hanamapure Deepa Narayan *","userId":"04442562197126563583"}},"outputId":"50dbd5c2-85ef-454b-d7c2-1c0b90eae747"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Running matrix multiplication for size 100x100x100\n","Serial execution time: 0.005033 seconds\n","CUDA execution time: 0.000117 seconds\n","Speedup: 43.017094\n","\n","Running matrix multiplication for size 500x500x500\n","Serial execution time: 0.759604 seconds\n","CUDA execution time: 0.001124 seconds\n","Speedup: 675.804270\n","\n","Running matrix multiplication for size 1000x1000x1000\n","Serial execution time: 7.171067 seconds\n","CUDA execution time: 0.007191 seconds\n","Speedup: 997.228063\n"]}]}]}